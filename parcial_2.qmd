---
title: "Parcial 2"
author: "Lauro Reyes 214532"
date: "2024-05-01"
output:
  pdf_document: default
  html_document: default
---

```{r,echo=FALSE,message=FALSE}
library(dplyr)
library(cmdstanr)
library(ggplot2)
library(bayesplot)
```

# Ejercicio 1

La siguiente tabla muestra el tamaño de muestra $n_i$ y el tiempo-medio-al-servicio $y_i$ (en segundos) para seis jugadores profesionales de tenis. Supongan que la media de la muestra para el jugador $i$ $y_i$ se distribuye normal con media $\mu_i$ y desviación estándar $\sigma/\sqrt{n_i}$ donde se supone que $\sigma$ = 5,5 segundos.

| Jugador | n   | ȳ     |
|---------|-----|-------|
| Murray  | 731 | 23.56 |
| Simon   | 570 | 18.07 |
| Federer | 491 | 16.21 |
| Ferrer  | 456 | 21.70 |
| Isner   | 403 | 22.32 |
| Kyrgios | 274 | 14.11 |

```{r}
data <- tibble(
  jugador = c('Murray', 'Simon', 'Federer', 'Ferrer', 'Isner', 'Kyrgios'),
  n = c(731, 570, 491, 456, 403, 274),
  y = c(23.56, 18.07, 16.21, 21.7, 22.31, 14.11)
)


calcular_intervalo <- function(samples) {
  # Extract the list of variable names
  var_names <- dimnames(samples)$variable
  ci_width_list <- list()

  for (var in var_names) {
    param_samples <- as.array(samples[, , var])
    param_samples_vector <- as.vector(param_samples)
    ci_bounds <- quantile(param_samples_vector, probs = c(0.05, 0.95))
    ci_width <- ci_bounds[2] - ci_bounds[1]
    ci_width_list[[var]] <- ci_width
  }
  
  return(ci_width_list)
}


```

## 1.a.

Se está interesado en estimar el tiempo-medio-al-servicio de Murray $\mu_1$ usando solo el tiempo al servicio de Murray. Supóngase que la creencia inicial sobre $\mu_1$ se representa por una densidad normal con media 20 y desviación estándar 10. Encontrar la distribución posterior de $\mu_1$ y construir un intervalo de credibilidad de 90 % para $\mu_1$.

```{r, message = FALSE, warning = FALSE}
model_code <- '
data {
  int<lower=0> n_obs;
  real y_obs;
}

parameters {
  real mu;
  real<lower=0> sigma;
}

model {
  // Priors
  mu ~ normal(20, 10);
  sigma ~ normal(0, 5.5);

  // Likelihood
  y_obs ~ normal(mu, sigma / sqrt(n_obs));
}

'
stan_model_path <- "models/ejercicio_1_a.stan"
writeLines(model_code, stan_model_path)

mod <- cmdstan_model(stan_model_path)
# datos
murray_data <- data %>% filter(jugador == "Murray")

data_list <- list(
  n_obs = murray_data$n,
  y_obs = murray_data$y
)

fit <- mod$sample(
  data = data_list,
  seed = 4,
  chains = 4,
)

mcmc_combo(fit$draws(), pars = c("mu"))

# intervalo
mu_samples <- fit$draws(variables = "mu")
mu_ci_murray <- calcular_intervalo(mu_samples)
print("Intervalo del 90% para \u03BC")
print(mu_ci_murray)

```

## 1.b

Suponer ahora que se cree que no hay diferencias entre los tiempos-medios-al servicio y $\mu_1$ = ... = $\mu_6$ = $\mu$. El tiempo-medio-al-servicio global es $\bar{y}$ = 19,9 con un tamaño de muestra combinado de $n = 2925$. Suponiendo que $\mu$ tiene una distribución inicial $N(20,10)$, encontrar la posterior de $\mu$ y construir un intervalo de credibilidad de 90 % para $\mu$.

```{r}
model_code <- "
data {
  real y_obs;
  int<lower=0> n_obs;
}

parameters {
  real mu;
  real<lower=0> sigma;
}

model {
  // Priors
  mu ~ normal(20, 10);
  sigma ~ normal(0, 5.5);

  // Likelihood
  y_obs ~ normal(mu, sigma / sqrt(n_obs));
}
"
stan_model_path <- "models/ejercicio_1_b.stan"
writeLines(model_code, stan_model_path)

mod <- cmdstan_model(stan_model_path)

# data
y_obs_all <- sum(data$y * data$n) / sum(data$n)
n_obs_all <- sum(data$n)

# Data list for Stan
data_list <- list(
  y_obs = y_obs_all,
  n_obs = n_obs_all
)

# Sampling
fit <- mod$sample(
  data = data_list,
  seed = 42,
  chains = 4)

print(fit$summary())
mcmc_combo(fit$draws(), pars = c("mu"))
# intervalo
mu_samples <- fit$draws(variables = "mu")
mu_ci <- calcular_intervalo(mu_samples)
print("Intervalo del 90% para \u03BC")
print(mu_ci)
```

## 1.c

¿Qué enfoque, parte (a) o parte (b), parece más razonable en esta situación?

**Depende de lo que necesites saber. Si quieres el tiempo promedio de todos buscando generalizar, usa el promedio total. Si te interesa el tiempo de un jugador específico, mira solo sus datos**

# Ejercicio 2

Continuando con el problema anterior, suponer que se quiere estimar el tiempo- medio-al servicio para los seis tenistas siguiendo un modelo jerárquico. Recordar que se supone $\sigma = 5,5$ segundos.

$\bar{y}_i \sim N(\mu_i,\sigma/\sqrt{n_i}), \quad i = 1,...,6$

$\mu_i \sim N(\mu,\tau), \quad i = 1,...,6$

$\mu \sim N(20,1/0.0001),$

$1/\tau^2 \sim G(0.01,0.1)$

## 2.a

Usar JAGS o Stan para simular una muestra de tamaño 1000 de la distribución posterior del modelo jerárquico.

```{r, warning=FALSE}
model_code <- '
data {
  int<lower=0> N;          
  vector[N] y;             
  vector<lower=0>[N] n;    
}

parameters {
  real mu;                 
  real<lower=0> inv_tau_squared;
  vector[N] mu_i;          
  real<lower=0> sigma;     
}

transformed parameters {
  real<lower=0> tau = sqrt(1 / inv_tau_squared);
}

model {
  // Priors
  mu ~ normal(20, 10);
  inv_tau_squared ~ gamma(0.01, 0.1);
  sigma ~ normal(0, 5.5);
  mu_i ~ normal(mu, tau);
  
  // Likelihood
  y ~ normal(mu_i, sigma ./ sqrt(n));
}
'

stan_model_path <- "models/ejercicio_2_a.stan"
writeLines(model_code, stan_model_path)

mod <- cmdstan_model(stan_model_path)

data_list <- list(
  N = nrow(data),
  y = data$y,
  n = data$n
)

# Sampling
fit <- mod$sample(
  data = data_list,
  seed = 4,
  chains = 4
)

fit$summary()
mcmc_combo(fit$draws(), pars = c("mu","tau","mu_i[1]"))
```

## 2.b

Construir un intervalo de credibilidad para cada una de las medias

```{r}
# intervalo
mu_samples <- fit$draws(variables = c("mu","mu_i[1]","mu_i[2]","mu_i[3]","mu_i[4]","mu_i[5]","mu_i[6]"))
mu_ci <- calcular_intervalo(mu_samples)
print(mu_ci) # intervalo del 90%
```

## 2.c

Comparar los intervalos de credibilidad para Murray con los intervalos obtenidos en el ejercicio 1.

```{r}
sprintf("Intervalo de confianza Murray (1): %.4f",mu_ci_murray)
sprintf("Intervalo de confianza Murray (2) [jerárquico]: %.4f",mu_ci$`mu_i[1]`)
```

# 3

Resolver el siguiente ejercicio. Pueden usar JAGS o Stan

Table 10.7 displays the number of fire calls and the number of building fires for ten counties in Montgomery County, Pennsylvania from 2015 through 2019. This data is currently described as Emergency - 911 Calls” from kaggle.com. Suppose that the number of building fires for the $j-th$ zip code is Poisson with mean $n_j \lambda_j$ where $n_j$ and $\lambda_j$ are respectively the number of fire calls and rate of building fires for the $j-th$ zip code.

Table 10.7. The number of fire calls and building fires for ten zip codes in Montgomery County, Pennsylvania.

| Zip Code | Fire Calls | ̄Building Fire  |
|----------|------------|----------------|
| 18054    | 266        | 12             |
| 18103    | 1          | 0              |
| 19010    | 1470       | 59             |
| 19025    | 246        | 11             |
| 19040    | 1093       | 47             |
| 19066    | 435        | 26             |
| 19116    | 2          | 0              |
| 19406    | 2092       | 113            |
| 19428    | 2025       | 73             |
| 19474    | 4          | 1              |

```{r}
fire_data <- tibble(
  zip_code = c(18054, 18103, 19010, 19025, 19040, 19066, 19116, 19406, 19428, 19474),
  fire_calls = c(266, 1, 1470, 246, 1093, 435, 2, 2092, 2025, 4),
  building_fire = c(12, 0, 59, 11, 47, 26, 0, 113, 73, 1)
)

# rates
fire_data <- fire_data %>%
  mutate(rate = if_else(building_fire > 0, fire_calls / building_fire, 0.001))
```

## 3.a

Suppose that the building fire rates $\lambda_1,\dots,\lambda_{10}$ follow a common $Gamma(\alpha, \beta)$ distribution where the hyperparameters $\alpha$ and $\beta$ follow weakly informative distributions. Use JAGS to simulate a sample of size 5000 from the joint posterior distribution of all parameters of the model.

```{r, warning=FALSE}
model_code <- '
data {
  int<lower=0> N;  
  vector<lower=0>[N] fire_calls;  
  array[N] int<lower=0> building_fires;  
}

parameters {
  real<lower=0> alpha;  
  real<lower=0> beta;  
  vector<lower=0>[N] lambda;  
}

transformed parameters {
  real building_fire_rate = alpha / beta;  
}

model {
  // Weakly informative priors for hyperparameters
  alpha ~ normal(0, 10);
  beta ~ normal(0, 10);

  
  lambda ~ gamma(alpha, beta);

  // Likelihood
  for (i in 1:N) {
    building_fires[i] ~ poisson(lambda[i] * fire_calls[i]);
  }
}
'
stan_model_path <- "models/ejercicio_3_a.stan"
writeLines(model_code, stan_model_path)

# Compile the model
mod <- cmdstan_model(stan_model_path)

# Create data list as per your dataset
data_list <- list(
  N = nrow(fire_data),
  fire_calls = fire_data$fire_calls,
  building_fires = fire_data$building_fire
)

# Sampling
fit <- mod$sample(
  data = data_list,
  seed = 1234,
  chains = 4,
  iter_sampling = 5000,
  iter_warmup = 1000
)

# Check the results
fit$summary()
mcmc_combo(fit$draws(), pars = c("alpha","beta"))
```

## 3.b

The individual estimates of the building rates for zip codes 18054 and 19010 are 12/266 and 59/1470, respectively. Contrast these estimates with the posterior means of the rates $\lambda_1$ and $\lambda_3$

```{r}
zip_18054_post_mean <- mean(fit$draws(variables = c("lambda[1]")))
zip_19010_post_mean <- mean(fit$draws(variables = c("lambda[3]")))
sprintf("Media de zip code 18054: %.4f , media posterior %.4f",12/266,zip_18054_post_mean)
sprintf("Media de zip code 19010: %.4f , media posterior %.4f",59/1470,zip_19010_post_mean)
```

## 3.c

The parameter $\mu = \alpha / \beta$ represents the mean building fire rates across zip codes. Construct a density estimate of the posterior distribution of $\mu$.

```{r}
mcmc_combo(fit$draws(), pars = c("building_fire_rate"))
```

## 3.d

Suppose that the county has 50 fire calls to the zip code 19066. Use the simulated predictive distribution to construct a 90% predictive interval for the number of building fires.

```{r}
model_code <- '
data {
  int<lower=0> fire_calls; 
}

parameters {
  real<lower=0> alpha; 
  real<lower=0> beta;  
  vector[3] lambda;    
}

generated quantities {
  int<lower=0> predicted_building_fires;
  real lambda_19066 = lambda[3];        
  predicted_building_fires = poisson_rng(lambda_19066 * fire_calls);
}
'
stan_model_path <- "models/ejercicio_3_d.stan"
writeLines(model_code, stan_model_path)

# Compilar el modelo
mod <- cmdstan_model(stan_model_path)

fit_pred <- mod$generate_quantities(
  data = list(fire_calls = 50),
  fitted_params = fit$draws(variables = c("alpha", "beta", "lambda"))
)
predicted_fires <- fit_pred$draws("predicted_building_fires")
predicted_fires_vector <- as.vector(predicted_fires)
quantiles <- quantile(predicted_fires_vector, probs = c(0.05, 0.95))
# Create a data frame for plotting
predicted_fires_df <- data.frame(predicted_fires = predicted_fires_vector)
# plot
ggplot(predicted_fires_df, aes(x = predicted_fires)) +
  geom_histogram(bins = 10, color = "black", fill = "gray", alpha = 0.3) +  # Normal histogram plot
  geom_histogram(data = predicted_fires_df %>% filter(predicted_fires >= quantiles[1] & predicted_fires <= quantiles[2]),
                 bins = 10, color = "black", fill = "red", alpha = 0.5) +  # Highlighted region
  labs(title = "Histogram of Predicted Building Fires with 90% Quantile Highlighted",
       x = "Number of Building Fires",
       y = "Count") +
  theme_minimal()
```
